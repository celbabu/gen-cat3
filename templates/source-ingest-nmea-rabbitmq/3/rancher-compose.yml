version: '2'

services:
  ingest-rabbitmq:
    scale: 1
    health_check:
      response_timeout: 2000
      healthy_threshold: 2
      port: 9000
      unhealthy_threshold: 3
      initializing_timeout: 120000
      interval: 30000
      strategy: recreate
      request_line: GET "/healthcheck" "HTTP/1.0"
      reinitializing_timeout: 120000
  decode-nmea:
    scale: 1
    health_check:
      response_timeout: 2000
      healthy_threshold: 2
      port: 9000
      unhealthy_threshold: 3
      initializing_timeout: 120000
      interval: 30000
      strategy: recreate
      request_line: GET "/healthcheck" "HTTP/1.0"
      reinitializing_timeout: 120000
  decode-ais:
    scale: 1
    health_check:
      response_timeout: 2000
      healthy_threshold: 2
      port: 9000
      unhealthy_threshold: 3
      initializing_timeout: 120000
      interval: 30000
      strategy: recreate
      request_line: GET "/healthcheck" "HTTP/1.0"
      reinitializing_timeout: 120000

catalog:
  name: "source-ingest-nmea-rabbitmq"
  version: "1.2.0"
  description: "The ingest NMEA stack consumes raw NMEA AIS reports from RabbitMQ, and decodes these messages generating MaritimeContacts."
  minimum_rancher_version: v0.51.0
  upgrade_from: "<1.2.0"
  questions:
    - variable: application_id
      label: "Application Id"
      required: true
      type: "string"
      description: "An alphanumeric string that uniquely identifies this application instance. WARNING: Applications deployed with the same Application ID that consume data from the same Kafka topic will have data split between them. See the Kafka documentation for APPLICATION_ID for further explanation." 
    - variable: kafka_service         
      description: "Kafka Stack/Service."
      label: "Kafka Broker to Connect to."                             
      required: false
      type: "service"
    - variable: schema_registry_service
      description: "Confluent Schema Registry Service."
      label: "Schema Registry"
      required: false
      type: "service"
    - variable: kafka_host 
      label: "Kafka Broker"
      required: true
      type: "string"
      default: "kafka"
    - variable: kafka_port 
      label: "Kafka Broker Port"
      required: true
      type: "int"
      default: "9092"
    - variable: schema_registry_url                                                                                                      
      label: "Schema Registry URL"
      required: true
      type: "string"
      default: "http://schema-registry:8081"
      description: "URL to a Confluent Schema Registry"
    - variable: provider
      label: "Provider"
      required: true
      type: "string"
      description: "A provider name that uniquely identitfies this source. (ie. ``coastal``)"

    - variable: rabbitmq_host
      label: "RabbitMQ Host"
      required: true
      type: "string"
    - variable: rabbitmq_port
      label: "RabbitMQ Port"
      required: true
      type: "int"

    - variable: rabbitmq_input_queue
      label: "RabbitMQ Input Queue"
      required: true
      type: "string"
      description: "The RabbitMQ queue that contains raw NMEAv4 data."
    
    - variable: rabbitmq_exchange
      label: "RabbitMQ Exchange"
      required: false
      type: "string"
    
    - variable: rabbitmq_authentication_enabled
      label: "Enable RabbitMQ Authentication"
      required: true
      type: "enum"
      options:
        - true
        - false
      default: "true"
      description: "This determines whether a RabbitMQ Usernabe/Password is utilized."

    - variable: rabbitmq_username
      label: "RabbitMQ Username"
      required: false
      type: "string"
      description: "The username field is required if RabbitMQ Authentication is set to 'true'"

    - variable: rabbitmq_password
      label: "RabbitMQ Password"
      required: false
      type: "string"
      description: "The password field is required if RabbitMQ Authentication is set to 'true'"
    
    - variable: rabbitmq_ssl_protocol
      label: "RabbitMQ SSL Protocol"
      required: true
      type: "enum"
      options:
        - true
        - false
        - TLS
        - SSLv3
      default: "true"

    - variable: kafka_output_topic_rawais
      label: "Kafka Output Topic (Raw AIS)"
      required: true
      type: "string"
      description: "The destination topic for raw textual AIS data. (Pipeline - This topic is ready by a downstream NMEAv4 decoder)."

    - variable: kafka_output_topic_avrorawais
      label: "Kafka Output Topic (Avro AIS)"
      required: true
      type: "string"
      description: "The destination topic for Avro Raw AIS data. (Pipeline - This topic is read by a downstream AIS Decoder)."

    - variable: kafka_output_topic_avromaritimecontact
      label: "Kafka Output Topic (Avro MaritimeContact)"
      required: true
      type: "string"
      description: "The destination topic for Avro MaritimeContact data."

    - variable: kafka_output_topic_avroaismaritimecontact
      label: "Kafka Output Topic (Avro AisMaritimeContact)"
      required: true
      type: "string"
      description: "The destination topic for Avro AisMaritimeContact data."

    - variable: num_stream_threads
      label: "Number Of Stream Threads"
      default: 1
      required: true
      type: "int"
      description: "The number of KStreams consumer threads to run. This value should be less than or equal to the number of partitions on the source kafka topic(s). (assuming a single instance of this microservice is running). If this value is set to 1 and there are 10 partitions on the source topic, all 10 partitions will be assigned to 1 thread; Records will be processed synchronously. If this value is set to 10 and there is only 1 partition on the source topic, then 9 threads will sit idle while 1 thread will process all records synchronously. Parallelism can only be acheived if the topic has >1 partition *AND* this value is >1."

    - variable: auto_offset_reset
      label: "Auto Offset Reset"
      required: true
      type: "enum"
      options:
        - latest
        - earliest
      default: "latest"
      description: "This determines where this application will start reading from on the input Kafak Topic on first startup. Once an application registers as a consumer on a topic, the read offset is tracked by Application Id."
    
    - variable: logging_level
      label: "The Log4J Logging Level"
      required: true
      type: "enum"
      options:
        - ALL
        - DEBUG
        - INFO
        - WARN
        - ERROR
        - FATAL
        - OFF
        - TRACE
      default: "INFO"
      description: "See Log4J documentation for further explanation of these levels."
      required: true
